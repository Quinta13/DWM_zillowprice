{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baeb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import math \n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn                 import tree\n",
    "from sklearn.tree            import DecisionTreeRegressor\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.preprocessing   import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils           import resample\n",
    "from sklearn.ensemble        import RandomForestRegressor\n",
    "\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db624492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local file paths\n",
    "fp_properties2016 = \"datasets/properties_2016.csv\"\n",
    "fp_properties2017 = \"datasets/properties_2017.csv\"\n",
    "fp_train2016      =   \"datasets/train_2016_v2.csv\"\n",
    "fp_train2017      =      \"datasets/train_2017.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5861da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "df_properties2016 = pd.read_csv(fp_properties2016, low_memory=False)\n",
    "df_train2016      = pd.read_csv(fp_train2016,      low_memory=False)\n",
    "df_properties2017 = pd.read_csv(fp_properties2017, low_memory=False)\n",
    "df_train2017      = pd.read_csv(fp_train2017,      low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f439c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print utilities\n",
    "def print_all(df):\n",
    "    pd.set_option('max_columns', df.shape[0])\n",
    "    pd.set_option('max_rows',    df.shape[1])\n",
    "def undo_print_all():\n",
    "    pd.set_option('max_columns', None)\n",
    "    pd.set_option('max_rows',    None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540676f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionalità\n",
    "print(f'Properites 2016 {df_properties2016.shape}')\n",
    "print(f'     Train 2016 {     df_train2016.shape}')\n",
    "print(f'Properites 2017 {df_properties2017.shape}')\n",
    "print(f'     Train 2017 {     df_train2017.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848037d",
   "metadata": {},
   "source": [
    "Non dispongono del log-error di ogni casa, ma solo di quelle che sono state vendute. <br>\n",
    "Seleziono solo l'insieme di case di cui ho a disposizione il log-error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af3975",
   "metadata": {},
   "source": [
    "Unione in un unico dataset: matengo le sole case di cui conosco il log-error <br>\n",
    "Se una casa ha più log-error, la colonna è copiata e abbinata a ciascuna data di vendita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right-join\n",
    "df_2016 = pd.merge(df_properties2016, df_train2016, how='right', left_on=['parcelid'], right_on=['parcelid'])\n",
    "df_2017 = pd.merge(df_properties2017, df_train2017, how='right', left_on=['parcelid'], right_on=['parcelid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Properites 2016 {df_2016.shape}')\n",
    "print(f'Properites 2017 {df_2017.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea246f1",
   "metadata": {},
   "source": [
    "Case vendute sia nel 2016 che nel 2017:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f67027",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(~(df_2017.loc[:,'parcelid'].isin(df_2016.loc[:,'parcelid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517740c",
   "metadata": {},
   "source": [
    "È importante tener presente che qualche migliaio di casa già venduta nel 2016 è stata venduta anche nel 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017[(df_2017.loc[:,'parcelid'].isin(df_2016.loc[:,'parcelid']))].loc[:,'parcelid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfde54c",
   "metadata": {},
   "source": [
    "La casa 12478591 è stata venduta due volte nel 2017 e almeno una volta nel 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f13cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_2016.loc[df_2016['parcelid'] == 12478591],\\\n",
    "           df_2017.loc[df_2017['parcelid'] == 12478591]]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_2016.loc[df_2016['parcelid'] == 12478591],\\\n",
    "           df_2017.loc[df_2017['parcelid'] == 12478591]])\\\n",
    "        .loc[:,['buildingqualitytypeid', 'structuretaxvaluedollarcnt', 'landtaxvaluedollarcnt', 'transactiondate', 'logerror']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ab78a",
   "metadata": {},
   "source": [
    "- __buildingqualitytypeid__ :  Overall assessment of condition of the building from best (lowest) to worst (highest)\n",
    "- __structuretaxvaluedollarcnt__ : The assessed value of the built structure on the parcel\n",
    "- __landtaxvaluedollarcnt__ : The assessed value of the land area of the parcel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67bbd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a2891",
   "metadata": {},
   "source": [
    "# Train, Validation e Test #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df_2016.columns)\n",
    "names.remove('logerror')\n",
    "print(names)\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678cdb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione in train, validation e test\n",
    "val_test_treshold = math.floor((len(df_2017) / 2)) # dimension of split betweween validation and test in df_2017\n",
    "train      = df_2016\n",
    "validation = df_2017.iloc[:val_test_treshold]\n",
    "test       = df_2017.iloc[val_test_treshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fc272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione in X e y\n",
    "train.loc[:,'logerror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d09f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(df, Xnames, yname):\n",
    "    X = df.loc[:,Xnames]\n",
    "    y = df.loc[:,yname]\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = split_X_y(train,      names, 'logerror')\n",
    "X_val,     y_val = split_X_y(validation, names, 'logerror')\n",
    "X_test,  y_test  = split_X_y(test,       names, 'logerror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionalità\n",
    "def dimensionality(y=False):\n",
    "    print(f'X_train {  X_train.shape}')\n",
    "    print(f'X_val   {    X_val.shape}')\n",
    "    print(f'X_test  {   X_test.shape}')\n",
    "    if y:\n",
    "        print(f'y_train { y_train.shape}')\n",
    "        print(f'y_val   {   y_val.shape}')\n",
    "        print(f'y_test  {  y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality(y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc435dee",
   "metadata": {},
   "source": [
    "# Preparazione dei dati #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded229d",
   "metadata": {},
   "source": [
    "## Rimozione colonne con alta percentuale di Nan ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the dataframe and the name of the column returns the column\n",
    "def get_col(df, colName):\n",
    "    return df.loc[:, colName]\n",
    "\n",
    "# Given a column returns Nan-count and Nan-percentage\n",
    "def get_col_nan_info(col):\n",
    "    count = col.isna().sum()\n",
    "    tot = len(col)\n",
    "    perc = count/tot\n",
    "    return count, perc\n",
    "\n",
    "# Given the df and a treshold returns a list of column names with Nan-percentage greater or equal the treshold\n",
    "def get_cols_over_nan_percentage(df, treshold):\n",
    "    names = df.columns\n",
    "    overPercentage = []\n",
    "    for name in names:\n",
    "        col = get_col(df, name)\n",
    "        _ , perc = get_col_nan_info(col)\n",
    "        # print(f'{name}: {perc})')\n",
    "        if perc > treshold:\n",
    "            overPercentage.append(name)\n",
    "    return overPercentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_delete = get_cols_over_nan_percentage(X_train, 0.6)\n",
    "\n",
    "for o in col_to_delete:\n",
    "    print(f'{o} : {get_col_nan_info(get_col(X_train, o))}')\n",
    "print(f'Length: {len(col_to_delete)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_column(df, col_names):\n",
    "    return df.drop(col_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28351b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, X_test]:\n",
    "    df = remove_column(df, col_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca86b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a3712",
   "metadata": {},
   "source": [
    "## Rimozione righe con molti Nan ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8dd2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the dataframe and the index of the row returns the row\n",
    "def get_row(df, index):\n",
    "    return df.loc[index, :]\n",
    "\n",
    "# Given a row returns Nan-count and Nan-percentage\n",
    "def get_row_nan_info(row):\n",
    "    count = row.isna().sum()\n",
    "    tot = len(row)\n",
    "    perc = count/tot\n",
    "    return count, perc\n",
    "\n",
    "# Given the df and a treshold returns a list of row ids with Nan-percentage greater or equal the treshold\n",
    "def get_rows_over_nan_percentage(df, treshold):\n",
    "    overPercentage_indexes = []\n",
    "    for i in df.index:\n",
    "        row = get_row(df, i)\n",
    "        _ , perc = get_row_nan_info(row)\n",
    "        if perc > treshold:\n",
    "            overPercentage_indexes.append(i)\n",
    "    return overPercentage_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_fullnan_rows(df, dfy, treshold):\n",
    "    indexes = get_rows_over_nan_percentage(df, treshold)\n",
    "    return df.drop(indexes, axis=0, inplace=True), dfy.drop(indexes, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality(y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab88fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for X, y in [[X_train, y_train], [X_val, y_val], [X_test, y_test]]:\n",
    "    X, y = drop_fullnan_rows(X, y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality(y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c86ae",
   "metadata": {},
   "source": [
    "Ho rimosso qualche decina di righe con prevalenza Nan dalle istanze di __Validation__ e __Test__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735226d",
   "metadata": {},
   "source": [
    "## Conversione di valor non numerici ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_numeric_cols(df):\n",
    "    \n",
    "    def is_numeric(value):\n",
    "        return value != np.int64 and\\\n",
    "               value != np.float64\n",
    "    \n",
    "    not_numeric = []\n",
    "    for k, v in dict(df.dtypes).items():\n",
    "        if(is_numeric(v)):\n",
    "            not_numeric.append(k)\n",
    "    return not_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_numeric = get_not_numeric_cols(X_train)\n",
    "print(not_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ada9b",
   "metadata": {},
   "source": [
    "Ho tre valori non numerici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# propertycountylandusecode\n",
    "values = get_col(X_train, 'propertycountylandusecode')\n",
    "print(f'Values:\\n{values.unique()      }\\n')\n",
    "print(f'Occurcences:\\n{values.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = get_col(X_train, 'propertyzoningdesc')\n",
    "print(f'Values:\\n{values.unique()      }\\n')\n",
    "print(f'Occurcences:\\n{values.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e31b47",
   "metadata": {},
   "source": [
    "Per queste due feature mantengo solo le dieci più frequenti: <br>\n",
    "Copro comunque l'informazione sulla maggioranza della popalazione, senza far esplodere il numero di colonne con il one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf16bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent(df, col_name, important):\n",
    "    col = get_col(df, col_name)\n",
    "    names = list(col.value_counts().to_dict().keys())[:important]\n",
    "    return names\n",
    "\n",
    "def set_other(df, col_name, important, dfs):\n",
    "    frequent = get_frequent(df, col_name, important)\n",
    "    for d in dfs:\n",
    "        d.loc[:,col_name][~d.loc[:,col_name].isin(frequent)] = 'rare'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_other(X_train, 'propertycountylandusecode', 5, [X_train, X_val, X_test])\n",
    "set_other(X_train, 'propertyzoningdesc',        5, [X_train, X_val, X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc09b1",
   "metadata": {},
   "source": [
    "Verifico se ho settatto correttamente l'etichetta *rare*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = get_col(X_train, 'propertycountylandusecode')\n",
    "print(f'Values:\\n{values.unique()      }\\n')\n",
    "print(f'Occurcences:\\n{values.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a2844",
   "metadata": {},
   "source": [
    "L'operazione sembra essere avvenuta correttamente :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactiondate\n",
    "values = get_col(X_train, 'transactiondate')\n",
    "print(f'Values:\\n{values.unique()      }\\n')\n",
    "print(f'Occurcences:\\n{values.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d865f",
   "metadata": {},
   "source": [
    "Trasformo i dati come informazioni sulla data dal 1 Gennaio di quell'anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d21de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_int(df, start):\n",
    "     \n",
    "    def string_to_date(date_str):\n",
    "        return dt.strptime(date_str.replace('-', '/'), '%Y/%m/%d')\n",
    "        \n",
    "    start = string_to_date(start)\n",
    "    df.loc[:,'int_transactiondate'] = ((pd.to_datetime(df.loc[:,'transactiondate'], format='%Y/%m/%d')))\n",
    "    df.loc[:,'int_transactiondate'] = (df.loc[:,'int_transactiondate'] - start).astype('timedelta64[D]')\n",
    "    df.drop('transactiondate', inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = date_to_int(X_train, start = '2016-01-01')\n",
    "X_val   = date_to_int(X_val,   start = '2017-01-01')\n",
    "X_test  = date_to_int(X_test,  start = '2017-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671447f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb404c",
   "metadata": {},
   "source": [
    "## Valori discreti ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrete(df, treshold):\n",
    "    discretes = []\n",
    "    for col_name in df.columns:\n",
    "        values_count = len(get_col(df,col_name).unique())\n",
    "        if values_count < treshold:\n",
    "            discretes.append(col_name)\n",
    "    return discretes\n",
    "\n",
    "def discrete_info(df, discretes):\n",
    "    for discrete in discretes:\n",
    "        values = get_col(df, discrete).unique()\n",
    "        print(f'{discrete}\\n{values} ({len(values)})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c614878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_info(X_train, get_discrete(X_train, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valori discreti: cateogirci e ordinali\n",
    "categorical = ['fips', 'heatingorsystemtypeid', 'propertycountylandusecode', 'propertylandusetypeid', 'propertyzoningdesc', 'regionidcounty']\n",
    "ordinal = ['bathroomcnt', 'bedroomcnt', 'buildingqualitytypeid', 'calculatedbathnbr', 'fullbathcnt', 'roomcnt', 'unitcnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droppo assessmentyear\n",
    "for df in [X_train, X_val, X_test]:\n",
    "    df = remove_column(df, 'assessmentyear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valori continui: numerici:\n",
    "numeric = list(set(X_train.columns) - set(categorical + ordinal) - {'parcelid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ad8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numeric) + len(categorical) + len(ordinal) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03538cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_check():\n",
    "    return X_train.shape[1] == len(numeric) + len(categorical) + len(ordinal) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90716a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Numeric:\\n{numeric} ({len(numeric)})\\n')\n",
    "print(f'Categorical:\\n{categorical} ({len(categorical)})\\n')\n",
    "print(f'Ordinal:\\n{ordinal} ({len(ordinal)})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c39832",
   "metadata": {},
   "source": [
    "# Correlazioni #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all(X_train)\n",
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "undo_print_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1535ee76",
   "metadata": {},
   "source": [
    "Nel modello sembrano esserci delle alte correlazioni, ad esempio tutti le feature che sembrano riguardare il numero di stanze e la grandezza della casa sembrano intevitabilmente correlate: al crescescere della grandezza della casa crescerà anche il numero di stanze che saranno distribuite in maniera pressochè omogenea tra le varia tipologie di stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16641f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated(df, col_name, treshold):\n",
    "    row = df.corr().loc[:, col_name]\n",
    "    list_ = list(row[abs(row)>treshold].to_dict().keys())\n",
    "    list_.remove(col_name)\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1702fc9",
   "metadata": {},
   "source": [
    "Controllo __finishedsquarefeet12__: Finished living area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_correlated(X_train, 'finishedsquarefeet12', 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee26e4",
   "metadata": {},
   "source": [
    "Come previsto, la grandezza della casa è formente correlata con il numero di stanze. Il numero di stanze è un'informazione ridontante che potrei eliminare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff32ce",
   "metadata": {},
   "source": [
    "Dalla descrizione ho che:\n",
    "- __bathroomcnt__:                   Number of bathrooms in home including fractional bathrooms\n",
    "- __bedroomcnt__:                    Number of bedrooms in home \n",
    "- __calculatedbathnbr__ :            Number of bathrooms in home including fractional bathroom\n",
    "- __calculatedfinishedsquarefeet__:  Calculated total finished living area of the home \n",
    "- __fullbathcnt__:                   Number of full bathrooms (sink, shower + bathtub, and toilet) present in home\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc69fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_to_squarefeet = ['bathroomcnt', 'bedroomcnt', 'calculatedbathnbr', 'calculatedfinishedsquarefeet', 'fullbathcnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, X_test]:\n",
    "    df = remove_column(df, related_to_squarefeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_from_categories(columns):\n",
    "    for to_delete in columns:\n",
    "        if to_delete in categorical:\n",
    "            categorical.remove(to_delete)\n",
    "        if to_delete in ordinal:\n",
    "            ordinal.remove(to_delete)\n",
    "        if to_delete in numeric:\n",
    "            numeric.remove(to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dad408",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_from_categories(related_to_squarefeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514703d",
   "metadata": {},
   "source": [
    "Noto anche che questa variabile è fortemente correlata con l'informazione legata alle tasse: è logico pensare che tanto più una casa sia grande, tanto più le tasse da pagare siano alte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0adf224",
   "metadata": {},
   "source": [
    "Studio __taxamount__: The total property tax assessed for that assessment year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_correlated(X_train, 'taxamount', 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9770565",
   "metadata": {},
   "source": [
    "Legati alle tasse:\n",
    "- __structuretaxvaluedollarcnt__: The assessed value of the built structure on the parcel\n",
    "- __taxvaluedollarcnt__: The total tax assessed value of the parcel\n",
    "- __landtaxvaluedollarcnt__: The assessed value of the land area of the parcel\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e5fbe5",
   "metadata": {},
   "source": [
    "Avendo queste quattro colonne una relazione, potrei pensare di riassumere l'informazione in due principali colonne: una per la tassa media e una per la tassa proporzionale al terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8679e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tax_info(df):\n",
    "    df['tax_ratio'] = df['taxvaluedollarcnt'] / df['taxamount']\n",
    "    df['tax_prop'] = df['structuretaxvaluedollarcnt'] / df['landtaxvaluedollarcnt']\n",
    "    if 'tax_ratio' not in numeric:\n",
    "        numeric.append('tax_ratio')\n",
    "    if 'tax_prop' not in numeric:\n",
    "        numeric.append('tax_prop')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3248ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_columns = ['taxamount', 'taxvaluedollarcnt', 'structuretaxvaluedollarcnt',  'landtaxvaluedollarcnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, X_test]:\n",
    "    df = add_tax_info(df)\n",
    "    df = remove_column(df, tax_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_from_categories(tax_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef4f13",
   "metadata": {},
   "source": [
    "## Missing Values: numerici e ordinali ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba7ae86",
   "metadata": {},
   "source": [
    "Controllo la percentuale di missing value in questi tipi di dati per controllare se è sensato inserire le missing-flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cn in numeric+ordinal:\n",
    "    col = get_col(X_train, cn)\n",
    "    _, perc = get_col_nan_info(col)\n",
    "    print(f'{cn}: {perc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6508850c",
   "metadata": {},
   "source": [
    "I missing value hanno una bassissima percentaule, scelgo di non usare i missing-flag, fatta eccezione per unitcnt. <br>\n",
    "Uso il missing flag per unitcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_flag(df, col_name):\n",
    "    df[col_name+'na_flag'] = df.loc[:,col_name].isna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80366b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for df in [X_train, X_val, X_test]:\n",
    "#    df = add_missing_flag(df, 'unitcnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f796df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['unitcnt_na_flag'] = X_train.loc[:,'unitcnt'].isna().astype(int)\n",
    "X_val['unitcnt_na_flag']   =   X_val.loc[:,'unitcnt'].isna().astype(int)\n",
    "X_test['unitcnt_na_flag']  =  X_test.loc[:,'unitcnt'].isna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ceed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_with_mean(df, col_names):   \n",
    "    for col_name in col_names:\n",
    "        df[col_name] = df[col_name].fillna(get_col(df, col_name).median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9155cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "undo_print_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b66e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fill_nan_with_mean(X_train, numeric+ordinal)\n",
    "X_val   = fill_nan_with_mean(  X_val, numeric+ordinal)\n",
    "X_test  = fill_nan_with_mean( X_test, numeric+ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric + ordinal].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511c8ca",
   "metadata": {},
   "source": [
    "## One-hot encoding delle variabili categoriali ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b32b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df_fit, col_names, dfs):\n",
    "    oh = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    oh.fit(df_fit[col_names])\n",
    "    for df in dfs:\n",
    "        encoded = oh.transform(df[col_names])\n",
    "        for i, col in enumerate(oh.get_feature_names(col_names)):\n",
    "            df[col] = encoded[:,i]\n",
    "        df.drop(col_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding(X_train, categorical, [X_train, X_val, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7628108f",
   "metadata": {},
   "source": [
    "Rimuovo colonne che codficano i Nan per One-Hot-Encoding: mantengo righe di soli zeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_column = list(filter(re.compile(\"^.*_nan$\").match, list(X_train.columns)))\n",
    "print(nan_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, X_test]:\n",
    "    df = remove_column(df, nan_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f007b",
   "metadata": {},
   "source": [
    "## Operazioni preliminari al modello ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e3d0f",
   "metadata": {},
   "source": [
    "Ora che ho mantenuto la corrispondenza di riga tra X e y è doveroso rimuovere il ParcelId: è un identificatore della riga e non un informazione utile all'algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9987d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, X_test]:\n",
    "    df = remove_column(df, ['parcelid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe613a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3f2bc",
   "metadata": {},
   "source": [
    "# Riassuntino dei dati #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f698b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1453fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77073d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0edc14b",
   "metadata": {},
   "source": [
    "# Costruzione DecisionTreeRegressor #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825702f",
   "metadata": {},
   "source": [
    "Uso validation per trovare il corretto numero di foglie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    def get_dec_tree_reg(max_leaf):\n",
    "        dt = DecisionTreeRegressor(max_leaf_nodes=max_leaf)\n",
    "        dt.fit(X_train,y_train)\n",
    "        return dt\n",
    "    \n",
    "    def get_train_val_mse(model):\n",
    "        return mean_squared_error(y_true=y_train, y_pred=model.predict(X_train)),\\\n",
    "               mean_squared_error(y_true=y_val,   y_pred=model.predict(X_val))\n",
    "    \n",
    "    start =   2\n",
    "    end   = 100\n",
    "    \n",
    "    model_start = get_dec_tree_reg(start)\n",
    "    \n",
    "    _, best_mse = get_train_val_mse(model_start)\n",
    "    \n",
    "    best_leaves = start\n",
    "    best_model  = model_start\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for max_leaves in range(start, end):\n",
    "    \n",
    "        model = get_dec_tree_reg(max_leaves)\n",
    "        train_mse, val_mse = get_train_val_mse(model)\n",
    "\n",
    "        errors.append(f'Leaves: {max_leaves} (Train MSE: {train_mse} - Val MSE: {val_mse})')\n",
    "\n",
    "        if(val_mse < best_mse):\n",
    "            best_mse = val_mse\n",
    "            best_leaves = max_leaves\n",
    "            best_model = model\n",
    "            \n",
    "    return model, best_leaves, errors       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, leaves, errors = validation(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feda60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d437ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_true=y_test,   y_pred=model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb173b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456933fa",
   "metadata": {},
   "source": [
    "# Random Forest #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3cfa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fallisci grazie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41426894",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
